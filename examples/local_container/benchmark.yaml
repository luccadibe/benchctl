# yaml-language-server: $schema=https://raw.githubusercontent.com/luccadibe/benchctl/main/cmd/schema/schema.json
benchmark:
  name: local-container-example
  output_dir: ./results

hosts:
  local: {}

stages:
  - name: build-docker-image
    host: local
    command: docker build -t local-container-server:latest .

  - name: start-container
    host: local
    command: |
      # Stop and remove any existing container
      docker stop local-container-server 2>/dev/null || true
      docker rm local-container-server 2>/dev/null || true
      
      # Start the new container
      docker run -d \
        --name local-container-server \
        -p 8080:8080 \
        -e BASE_DELAY=100 \
        -e VARIANCE=50 \
        -e ERROR_RATE=0.05 \
        local-container-server:latest
    health_check:
      type: port
      target: "8080"
      timeout: 30s
      retries: 10

  - name: resource-monitor
    host: local
    command: ./scripts/resource_monitor.sh /tmp/resource_monitor.csv
    background: true
    outputs:
      - name: resource_monitor
        remote_path: /tmp/resource_monitor.csv
        local_path: ./results/resource_monitor.csv
        data_schema:
          format: csv
          columns:
            - name: timestamp_ms
              type: timestamp
              unit: ms
              format: unix_ms
            - name: cpu_used_raw
              type: integer
            - name: cpu_total_raw
              type: integer
            - name: cpu_percent
              type: integer
            - name: mem_used_bytes
              type: integer
              unit: bytes
            - name: mem_total_bytes
              type: integer
              unit: bytes
            - name: mem_percent
              type: integer

  - name: run-load-test
    host: local
    script: load_generator.sh
    outputs:
      - name: load_test_results
        remote_path: /tmp/load_test_results.csv
        local_path: ./results/load_test_results.csv
        data_schema:
          format: csv
          columns:
            - name: timestamp
              type: timestamp
              unit: s
            - name: latency_ms
              type: float
              unit: ms
            - name: status
              type: string
            - name: response_time_ms
              type: float
              unit: ms

  - name: cleanup-container
    host: local
    command: |
      docker stop local-container-server || true
      docker rm local-container-server || true
      echo "Container cleaned up successfully"

  - name: analyse_csv
    host: local
    command: |
      uv run ./scripts/analyse_csv.py
    append_metadata: true

plots:
  - name: latency_over_time
    title: Request Latency Over Time
    source: load_test_results
    type: time_series
    x: timestamp
    y: latency_ms
    format: png
    export_path: ./plots/latency_over_time.png
    engine: seaborn
    options:
      style: whitegrid
      dpi: 150
      width_px: 1200
      height_px: 600
      x_label_angle: 45
      x_timestamp_format: medium

  - name: latency_distribution
    title: Latency Distribution
    source: load_test_results
    type: histogram
    x: latency_ms
    format: png
    export_path: ./plots/latency_distribution.png
    engine: seaborn
    options:
      style: whitegrid
      bins: 30

  - name: latency_boxplot
    title: Server Latency by Task Type
    source: load_test_results
    type: boxplot
    x: task_type
    y: latency_ms
    format: png
    export_path: ./plots/latency_boxplot.png
    engine: seaborn
    options:
      style: whitegrid

  - name: resource_cpu_time
    title: CPU Utilization During Benchmark
    source: resource_monitor
    type: time_series
    x: timestamp_ms
    y: cpu_percent
    format: png
    export_path: ./plots/resource_cpu_time.png
    engine: seaborn
    options:
      style: whitegrid
      x_timestamp_format: medium
      x_label_angle: 45
      dpi: 150
      width_px: 1200
      height_px: 400
